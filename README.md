# ODPC-RAG

A Retrieval-Augmented Generation (RAG) chatbot for the Office of the Data Protection Commissioner (ODPC) Kenya. This system crawls web data, indexes documents into a vector store, and provides both CLI and API interfaces for querying data protection information.

## Requirements

- Python 3.10+
- Virtual environment tool (venv, conda, etc.)
- Internet access for crawling and API calls

## Installation

```bash
# Clone the repository
git clone https://github.com/peter-kiilu/ODPC-RAG.git
cd ODPC-RAG

# Create and activate virtual environment
python -m venv .venv
source .venv/bin/activate   # macOS/Linux
# .venv\Scripts\activate    # Windows

# Install dependencies
pip install -r requirements.txt
```

## Configuration

Create a `.env` file in the project root with your API keys:

```env
GROQ_API_KEY=your_groq_api_key_here
# Add other environment variables as needed
```

## Usage

### 1. Crawl Web Data

Download and collect web content:

```bash
# Remove existing state for fresh crawl (optional)
rm crawler_state.json

# Start crawler
python -m crawler.crawler
```

### 2. Index Documents

Build the vector database from crawled content:

```bash
python -m rag_bot.main index

# Or clear existing index and re-index
python -m rag_bot.main index --clear
```

### 3. Chat Interface (CLI)

Interact with the chatbot via command line:

```bash
python -m rag_bot.main chat
```

Available commands:
- Type your question to get answers
- `clear` - Reset conversation history
- `quit` or `exit` - Close the chat

### 4. API Server (Optional)

Expose the chatbot via HTTP API:

```bash
uvicorn rag_bot.api:app --reload --host 0.0.0.0 --port 8000
```

**API Endpoints:**
- `GET /health` - Check system status
- `POST /chat` - Send message and get response
- `POST /clear` - Clear conversation history

**Example API request:**
```bash
curl -X POST "http://localhost:8000/chat" \
  -H "Content-Type: application/json" \
  -d '{"message": "What are data subject rights in Kenya?"}'
```

## Project Structure

```
ODPC-RAG/
â”œâ”€â”€ crawler/              # Web crawling module
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ crawler.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ rag_bot/              # RAG chatbot implementation
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ api.py            # FastAPI server
â”‚   â”œâ”€â”€ chat.py           # Chat logic
â”‚   â”œâ”€â”€ chunker.py        # Text chunking
â”‚   â”œâ”€â”€ config.py         # Configuration
â”‚   â”œâ”€â”€ document_loader.py # Document loading
â”‚   â”œâ”€â”€ embeddings.py     # Embedding generation (GPU-enabled)
â”‚   â”œâ”€â”€ main.py           # CLI entry point
â”‚   â”œâ”€â”€ prompts.py        # Prompt templates
â”‚   â”œâ”€â”€ retriever.py      # Document retrieval
â”‚   â””â”€â”€ vector_store.py   # ChromaDB vector database
â”œâ”€â”€ frontend/             # React frontend (optional)
â”œâ”€â”€ data/                 # Crawled documents storage
â”œâ”€â”€ venv/                 # Virtual environment
â”œâ”€â”€ .env                  # Environment variables
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ my_changes.patch
```

## Troubleshooting

**Module not found errors:**
- Ensure virtualenv is activated
- Run commands from project root

**Crawler issues:**
- Check network connectivity
- Delete `crawler_state.json` for fresh start

**Indexing failures:**
- Verify API keys in `.env`
- Check internet connectivity

**CORS errors (API):**
- Update `origins` list in `rag_bot/api.py`
- For Cloud Workstations, add `credentials: 'include'` in frontend fetch requests

## Features

- ğŸ” **RAG-powered Q&A** - Answers based on indexed ODPC documents
- ğŸŒ **Multi-language support** - English, Swahili, and Sheng
- ğŸ’¬ **Conversation history** - Maintains context across questions
- ğŸ›¡ï¸ **Topic boundaries** - Focused on data protection topics only
- ğŸš€ **GPU acceleration** - Automatic GPU detection for embeddings
- ğŸ“Š **Source citations** - Tracks and displays information sources

## License

Check the repository for LICENSE file.

## Contributing

Contributions welcome! Please:
- Follow existing code style
- Add tests for new features
- Keep changes focused and well-documented
